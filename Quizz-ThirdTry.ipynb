{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is from: https://www.geeksforgeeks.org/linear-regression-python-implementation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n",
      "Variance score: 0.7406426641094095\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn import datasets, linear_model, metrics \n",
    "  \n",
    "# load the boston dataset \n",
    "boston = datasets.load_boston(return_X_y=False) \n",
    "  \n",
    "# defining feature matrix(X) and response vector(y) \n",
    "X = boston.data \n",
    "y = boston.target \n",
    "  \n",
    "# splitting X and y into training and testing sets \n",
    "#from sklearn.model_selection import train_test_split \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, \n",
    "#                                                    random_state=1) \n",
    "  \n",
    "# create linear regression object \n",
    "reg = linear_model.LinearRegression() \n",
    "  \n",
    "# train the model using the training sets \n",
    "reg.fit(X, y) \n",
    "  \n",
    "# regression coefficients \n",
    "print('Coefficients: \\n', reg.coef_) \n",
    "  \n",
    "# variance score: 1 means perfect prediction \n",
    "print('Variance score: {}'.format(reg.score(X, y))) \n",
    "  \n",
    "# plot for residual error \n",
    "  \n",
    "## setting plot style \n",
    "#plt.style.use('fivethirtyeight') \n",
    "  \n",
    "## plotting residual errors in training data \n",
    "#plt.scatter(reg.predict(X_train), reg.predict(X_train) - y_train, \n",
    "#            color = \"green\", s = 10, label = 'Train data') \n",
    "  \n",
    "## plotting residual errors in test data \n",
    "#plt.scatter(reg.predict(X_test), reg.predict(X_test) - y_test, \n",
    "#            color = \"blue\", s = 10, label = 'Test data') \n",
    "  \n",
    "## plotting line for zero residual error \n",
    "#plt.hlines(y = 0, xmin = 0, xmax = 50, linewidth = 2) \n",
    "  \n",
    "## plotting legend \n",
    "#plt.legend(loc = 'upper right') \n",
    "  \n",
    "## plot title \n",
    "#plt.title(\"Residual errors\") \n",
    "  \n",
    "## function to show plot \n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 36.459488385089855\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: \\n', reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: \n",
      " 0.7406426641094095\n"
     ]
    }
   ],
   "source": [
    "print('R^2 score: \\n', reg.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last things are from here: https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
